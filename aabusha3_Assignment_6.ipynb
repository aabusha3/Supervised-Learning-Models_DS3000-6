{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fykhFKa3Ulnh"
   },
   "source": [
    "# Assignment 6 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "370AKC5oUxsB"
   },
   "source": [
    "This notebook contains the questions for Assignment 6. \n",
    "\n",
    "Please note, a random seed has been set to ensure the reproducibility of the results -- *DO NOT* change this random seed. **If you call additional functions that are based on random number generators, you will need to define their seed to 42 as well**. \n",
    "\n",
    "Make sure to complete this assignment individually and appropriately reference all external code and documentation used. ***In order for your submission to be valid, you must adhere to the function definitions which have been made (failure to do so will result in a grade of 0). You must upload this completed Jupyter Notebook file as your submission (other file types are not permitted and will result in a grade of 0).*** You are responsible for selecting and importing additional packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "45VAP00lUkc5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "e9fI_lLV3MhP"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier,BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, recall_score, precision_score, confusion_matrix\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3YmD_jy2VkV5"
   },
   "source": [
    "## Dataset Description\n",
    "\n",
    "Attached with the assignment instructions, you will find the datasets.zip file. After unzipping the file, you will find two .csv files, where each file represents real-world measurement data of a heat experiment inside a steel furnace. \"normal.csv\" has all the normal experimental samples, while \"anomalous.csv\" has all the abnormal experimental samples.\n",
    "\n",
    "In the datasets, the features are the vibration measurements in columns A, B, ... , H, which correspond to (X1, X2, ... , X8) measurement signals. Each feature represents a vibration signal inside the furnace at several frequency bands. Each example is a measurement recorded at a time instance (Timestamp), which are considered time-series data measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UD1u-9MwVY5k"
   },
   "source": [
    "## Question 1 - Data Preparations [10 Marks]\n",
    "\n",
    "A) Read \"normal.csv\" as a pandas dataframe \"normalData\", and print out the shape of the normal dataset.\n",
    "\n",
    "B) Read \"anomalous.csv\" as a pandas dataframe \"anomalousData\", and print out the shape of the nomalous dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VYa70oGzXmbl"
   },
   "outputs": [],
   "source": [
    "### Q1A) - 5pts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "T2EbZ-FwYIGl"
   },
   "outputs": [],
   "source": [
    "### Q1B) - 5pts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A2LBEIAJYQV1"
   },
   "source": [
    "## Question 2 - Supervised Learning Algorithms [50 Marks]\n",
    "\n",
    "A) Complete the myTrainTestSplit function, which takes as input **two dataframes** consisting of the normal and anomalous datasets, reserves 30 percent of each dataframe for testing and **returns 4 variables, Xtrain, Xtest, ytrain, and ytest**. \n",
    "\n",
    "*Note: you can use `concat` from pandas library to concatenade trainig sets from two dataframes, and test sets from two dataframes.*\n",
    "\n",
    "\n",
    "B) Apply a Decision Tree model for classifying the events as normal or anomalous. Fill in the myDecisionTree function, which accepts as input the training set and returns a fully trained model. \n",
    "\n",
    "C) Apply a Bagging model that consists of 10 base decision trees for classifying the events as normal or anomalous. Fill in the myBagging function, which accepts as input the training set and returns a fully trained model. \n",
    "\n",
    "D) Apply a Random Forest model that consists of 10 base decision trees for classifying the events as normal or anomalous. Fill in the myRandomForest function, which accepts as input the training set and returns a fully trained model. \n",
    "\n",
    "E) Based on the trained Random Forest model from 2D, use a horizontal bar plot to plot the feature importance scores of all features (Timestamp, X1-X8).\n",
    "\n",
    "F) Fill in the myEvaluateSupervisedModelPerformance function, which takes as input the training and test sets. Please note, you will need to call your functions from 2B, 2C, and 2D within this function to train your models. \n",
    "- Calculate the training time for comparing models. \n",
    "- Evaluate the performance of your models using 3 metrics of `Recall`, `Preceision` and `f1 score`. Return three numpy arrays consisting of the three metrics calculated for each model on the test set and print them out. \n",
    "- Also, print out the confusion matrix of your three models on the test set. \n",
    "\n",
    "G) **Written Answer** - Use the markdown cell to answer the following:\n",
    "- Justify the choice of three metrics for the evaluation of the model's performance.\n",
    "- Compare the performance and training time of the Decision Tree and Bagging models and discuss the reasons for the performance difference.\n",
    "- Compare the performance and training time of the Bagging and Random Forest models and discuss the reasons for the performance difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7kC7gNWGQbC1"
   },
   "outputs": [],
   "source": [
    "### Q2A) - 5pts \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q2B) - 5pts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q2C) - 5pts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Rdw3xDzGZdAb"
   },
   "outputs": [],
   "source": [
    "### Q2D) - 5pts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q2E) - 10pts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Q2F) - 10pts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2G) - 10 pts\n",
    "\n",
    "**Witten Answer:** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 - Dimensionality Reduction [40 Marks]\n",
    "\n",
    "A) Build the pipeline that uses a Principal Component Analysis (PCA) model to extract 2 principal components of the training set and create a a Random Forest model that consists of 50 base decision trees (same as the model in 2D).  Fill in the myPCARF function, which accepts as input the training set and returns a fully trained model. \n",
    "\n",
    "B) Fill in the myEvaluateUnsupervisedModelPerformance function, which takes as input the training and test sets. Please note, you will need to call your functions from 3A within this function to train your models. \n",
    "- Calculate the training time for comparing models. \n",
    "- Evaluate the performance of your model on the test set using the 3 same metrics from 2F. Return three numpy arrays consisting of the three metrics calculated for the model and print them out. \n",
    "- Also, print out the confusion matrix of your model on the test set. \n",
    "\n",
    "*Note: This function can be the same as the function from 2F, but remember to change the model name.*\n",
    "\n",
    "C) **Written Answer** - Use the markdown cell to answer the following:\n",
    "- Compare the performance and training time of PCA + Random Forest model from 3A and the Random Forest model from 2D, and discuss the reasons for the performance difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q3A) - 10pts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ldPs5xBRa7Q5",
    "outputId": "223857e9-24a7-4889-b543-1300726f575f"
   },
   "outputs": [],
   "source": [
    "### Q3B) - 5pts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ttLtyLi1b0IE"
   },
   "source": [
    "#### Q3C) - 10 pts\n",
    "\n",
    "**Written Answer:**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "3YmD_jy2VkV5",
    "ttLtyLi1b0IE",
    "tLUT1nMwdYKw"
   ],
   "name": "ECE9309_9039_Assignment2_2022.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
